{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis of IMDB Movie Reviews (Part 3: BERT model)"
      ],
      "metadata": {
        "id": "1zi7CTVbfo8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Important: Pre-trained transformer models like BERT from Hugging Face are designed to handle text in its raw form!\n",
        "\n",
        "Side note: I was using pytorch BERT transfomer(`from transformers import BertModel`, `from transformers import BertTokenizer`) with data processing (e.g. stemming, strip html...). Yet, the model either doesn't run or take more than 1 hr because of the big dataset. Hence, I follow [this tutorial](https://huggingface.co/blog/sentiment-analysis-python) to implement a BERT model. \n",
        "\n"
      ],
      "metadata": {
        "id": "MAwOXDjcv66k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9__Fs1UB4ihV"
      },
      "source": [
        "## BERT model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySOAncvV4ihV"
      },
      "source": [
        "### What's special about BERT? \n",
        "- Context-free models:generate a single word embedding representation for each word in the vocabulary,  such as word2vec or GloVe. For example, the word “bank” would have the same representation in “bank deposit” and in “riverbank”\n",
        "- Contextual models instead generate a representation of each word that is based on the other words in the sentence, such as BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9tiuYi44ihV"
      },
      "source": [
        "### Understand how BERT works\n",
        "1. Token embeddings: A [CLS] token is added to the input word tokens at the beginning of the first sentence and a [SEP] token is inserted at the end of each sentence.\n",
        "2. Segment embeddings: A marker indicating Sentence A or Sentence B is added to each token. **This allows the encoder to distinguish between sentences.**\n",
        "3. Positional embeddings: A positional embedding is added to each token to indicate its position in the sentence.\n",
        "\n",
        "![BERT model structure](https://towardsml.files.wordpress.com/2019/09/input.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iusClXns4ihW"
      },
      "source": [
        "1. Masked LM (MLM)\n",
        "The idea here is “simple”: Randomly mask out 15% of the words in the input — replacing them with a [MASK] token.  Loss function considers only the prediction of the masked tokens and ignores the prediction of the non-masked ones.\n",
        "\n",
        "2. Next Sentence Prediction (NSP)\n",
        "In order to understand relationship between two sentences, BERT training process also uses next sentence prediction, BERT separates sentences with a special [SEP] token. During training the model is fed with two input sentences at a time such that:\n",
        "- 50% of the time the second sentence comes after the first one.\n",
        "- 50% of the time it is a a random sentence from the full corpus.\n",
        "\n",
        "Example: predict if the next sentence is random or not \n",
        "\n",
        "![BERTseq](https://towardsml.files.wordpress.com/2019/09/nsp-1.png)\n",
        "\n",
        "\n",
        "Important note: BERT does not try to predict the next word in the sentence!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIbC2Mx_4ihW"
      },
      "source": [
        "### Tokenizer for BERT\n",
        "\n",
        "BERT uses what is called a WordPiece tokenizer. It works by splitting words either into the full forms (e.g., one word becomes one token) or into word pieces — where one word can be broken into multiple tokens.\n",
        "\n",
        "| Word          | Token(s)                           |\n",
        "| ------------- | ---------------------------------- |\n",
        "| surf          | \\['surf'\\]                         |\n",
        "| surfing       | \\['surf', '##ing'\\]                 |\n",
        "| surfboarding  | \\['surf', '##board', '##ing'\\]       |\n",
        "| surfboard     | \\['surf', '##board'\\]               |\n",
        "| snowboard     | \\['snow', '##board'\\]               |\n",
        "| snowboarding  | \\['snow', '##board', '##ing'\\]       |\n",
        "| snow          | \\['snow'\\]                         |\n",
        "| snowing       | \\['snow', '##ing'\\]                 |\n",
        "\n",
        "By splitting words into word pieces, we have already identified that the words \"surfboard\" and \"snowboard\" share meaning through the wordpiece \"##board\" We have done this without even encoding our tokens or processing them in any way through BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GYhd7Ec4ihW"
      },
      "source": [
        "### BERT model choice\n",
        "BERT model we choose \n",
        "**DistilBERT** vs BERT\n",
        "- DistilBERT is a small, fast, cheap and light Transformer model trained by distilling BERT base. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark.\n",
        "\n",
        "**BERT-base** vs BERT-large: BERT-based\n",
        "- BERT-Base: 12-layer, 768-hidden-nodes, 12-attention-heads, 110M parameters\n",
        "- BERT-Large: 24-layer, 1024-hidden-nodes, 16-attention-heads, 340M parameters\n",
        "\n",
        "BERT-based-case vs **BERT-base-uncased**:\n",
        "- We don't differentiate between cased and uncased data (english vs English)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5OoUJ-e4ihW"
      },
      "source": [
        "### BERT input \n",
        "\n",
        "Input IDs – The input ids are often the only required parameters to be passed to the model as input. Token indices, numerical representations of tokens building the sequences that will be used as input by the model.\n",
        "\n",
        "Attention mask – Attention Mask is used to avoid performing attention on padding token indices. Mask value can be either 0 or 1, 1 for tokens that are NOT MASKED, 0 for MASKED tokens.\n",
        "\n",
        "Token type ids – It is used in use cases like sequence classification or question answering. As these require two different sequences to be encoded in the same input IDs. Special tokens, such as the classifier[CLS] and separator[SEP] tokens are used to separate the sequences.\n",
        "\n",
        "\n",
        "Note: Padding is a special form of masking where the masked steps are at the start or the end of a sequence. Padding comes from the need to encode sequence data into contiguous batches: in order to make all sequences in a batch fit a given standard length, it is necessary to pad or truncate some sequences\n",
        "\n",
        "### BERT tokens\n",
        "\n",
        "`CLS`: The [CLS] token, short for \"classification,\" is a special token used in BERT to represent the entire input sequence for classification tasks. \n",
        "\n",
        "When training a classification model using BERT, the [CLS] token is added to the beginning of the input sequence, and the final hidden state corresponding to this token is used as the input to a classifier. This allows the model to make a prediction for the entire input sequence.\n",
        "\n",
        "`SEP`: The [SEP] token, short for \"separator,\" is used to separate two different segments of a sentence or document. \n",
        "\n",
        "In BERT, the [SEP] token is used to separate the two segments when performing tasks like question answering or natural language inference, where the model needs to understand the relationship between two different segments of text.\n",
        "\n",
        "`MASK`: [MASK] is used during pre-training to randomly mask some of the input tokens, forcing the model to learn to predict the masked tokens based on the surrounding context.\n",
        "\n",
        "![image](https://editor.analyticsvidhya.com/uploads/79452bert-text-classification-input.width-1280.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfDX-AKQ4ihW"
      },
      "source": [
        "### Understanding the parameters \n",
        "`max_length` is a parameter used to define the maximum length of an input sequence. \n",
        "\n",
        "`pad_to_max_length` is a Boolean parameter used to indicate whether sequences shorter than the max_length should be padded with a special token, usually [PAD], to make them the same length as the longest sequence in the batch. \n",
        "\n",
        "`return_tensors` parameter specifies that we want the encoded data to be returned as TensorFlow tensor\n",
        "\n",
        "`attention_mask`: 1 indicates a value that should be attended to, while 0 indicates a padded value. \n",
        "\n",
        "Example: \n",
        "\n",
        "`sequence_a = \"This is a short sequence.\"`\n",
        "`sequence_b = \"This is a rather long sequence. It is at least longer than the sequence A.\"`\n",
        "`len(encoded_sequence_a), len(encoded_sequence_b)`\n",
        "\n",
        "(8, 19)\n",
        "\n",
        "`padded_sequences = tokenizer([sequence_a, sequence_b], padding=True)`\n",
        "`padded_sequences[\"input_ids\"]`\n",
        "\n",
        "[[101, 1188, 1110, 170, 1603, 4954, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1188, 1110, 170, 1897, 1263, 4954, 119, 1135, 1110, 1120, 1655, 2039, 1190, 1103, 4954, 138, 119, 102]]\n",
        "\n",
        "`padded_sequences[\"attention_mask\"]`\n",
        "\n",
        "[[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: We use huggingface model and setup packeages to have a clear view on the tranining process. "
      ],
      "metadata": {
        "id": "ktOtH6TfYFme"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgtj5vZX4ihX"
      },
      "source": [
        "Resources\n",
        "- [BERT Explained: A Complete Guide with Theory and Tutorial](https://towardsml.wordpress.com/2019/09/17/bert-explained-a-complete-guide-with-theory-and-tutorial/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6MhwwiU4ihX"
      },
      "source": [
        "### BERT vs RoBERTa\n",
        "\n",
        "RoBERTa model shares the same architecture as the BERT model. It is a reimplementation of BERT with some modifications to the key hyperparameters and minor embedding tweaks.\n",
        "\n",
        "\n",
        "The key differences between RoBERTa and BERT can be summarized as follows:\n",
        "\n",
        "- RoBERTa is a reimplementation of BERT with some modifications to the key hyperparameters and minor embedding tweaks. It uses a byte-level BPE as a tokenizer (similar to GPT-2) and a different pretraining scheme.\n",
        "- RoBERTa is trained for longer sequences, too, i.e. the number of iterations is increased from 100K to 300K and then further to 500K.\n",
        "- RoBERTa uses larger byte-level BPE vocabulary with 50K subword units instead of character-level BPE vocabulary of size 30K used in BERT.\n",
        "- In the Masked Language Model (MLM) training objective, RoBERTa employs dynamic masking to generate the masking pattern every time a sequence is fed to the model.\n",
        "- RoBERTa doesn’t use token_type_ids, and we don’t need to define which token belongs to which segment. Just separate segments with the separation token tokenizer.sep_token (or ).\n",
        "- The next sentence prediction (NSP) objective is removed from the training procedure.\n",
        "- Larger mini-batches and learning rates are used in RoBERTa’s training.\n",
        "\n",
        "In the future, we can consider using RoBERTa because it is supposed to have better results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "OLetGEY6XKNn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg5Q9mEgtPmD",
        "outputId": "1a24544d-b39b-4914-923d-ea76d500c64e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#make sure we are using GPU to run \n",
        "\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "YfY9L9Sr-dES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "45376bfead714e4e97a1c847a987c130",
            "2c56a71fad5749cfa0f9b6c1417b2ed1",
            "f804785d4e394a06ae42016103b36978",
            "2ec2e33a2f564fad9f64b9f61e26af45",
            "36158f90e78e4a96bca13c6be0423782",
            "fbe932fe87464453829335ade961855e",
            "85bd186181364ab0aaa3e5c3edadda79",
            "f42f8e8b73ff48b9a7c99a0e2e2ec470",
            "c34fe42478a14ee4955ee8b786c1f647",
            "ec615df4324c4c99bec0e2c0c350525a",
            "9ff48cf86c0546759c648b838498a004"
          ]
        },
        "id": "zH7R5NCRtPmH",
        "outputId": "357cec8d-9041-4427-8147-4015794046d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45376bfead714e4e97a1c847a987c130"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "imdb = load_dataset(\"imdb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1YUKpUytPmH",
        "outputId": "fb24186d-fc1e-4108-a0fc-c90cfc1e2d80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-9c48ce5d173413c7.arrow\n"
          ]
        }
      ],
      "source": [
        "#take only 1000 training data but all of the testing data\n",
        "\n",
        "small_train_dataset = imdb[\"train\"].shuffle(seed=42).select([i for i in list(range(1000))])\n",
        "small_test_dataset = imdb[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DJ2VbCcuIJe",
        "outputId": "1ac4ef02-e8cc-4efe-a08f-b86c79ff308b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "01a545d65439435f93c79dc952329df4",
            "e21f08cc1b6e46a0866b936340c907ec",
            "8f306f051830410ebc33a7576251a586",
            "c56b717e10d14f15b0adfdb31bd48942",
            "c25c6d0a8d014848a4836a3eae8e4c3d",
            "a5311314d4af4547af732f275bd34aa5",
            "2a41816676a5466889cd978fc8eb3c40",
            "c06a6ecb5e5e4a739d4fad05e8527353",
            "418353e277fb4727ad09ddf600d23637",
            "aa5eb9691a974d4d9f9b15084f6a5ac9",
            "236b5fa8480d4e5aaedede12905e256e"
          ]
        },
        "id": "lYEz02EctPmI",
        "outputId": "f2277cb2-5140-438a-f242-caa40c934c33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-916b6147aa954289.arrow\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01a545d65439435f93c79dc952329df4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "def preprocess_function(examples):\n",
        "   return tokenizer(examples[\"text\"], truncation=True)\n",
        " \n",
        "tokenized_train = small_train_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_test = small_test_dataset.map(preprocess_function, batched=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnyzqSN8tPmJ",
        "outputId": "272d623b-96ff-4b71-dd38-46686b2e9529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/pytorch_model.bin\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        " \n",
        "def compute_metrics(eval_pred):\n",
        "   load_accuracy = load_metric(\"accuracy\")\n",
        "   load_f1 = load_metric(\"f1\")\n",
        "  \n",
        "   logits, labels = eval_pred\n",
        "   predictions = np.argmax(logits, axis=-1)\n",
        "   accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "   f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
        "   return {\"accuracy\": accuracy, \"f1\": f1}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_Jtv17itPmK",
        "outputId": "a19b7754-8eec-4684-83e3-6124cc6a60de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        " \n",
        "repo_name = \"finetuning-sentiment-model-1000-samples\"\n",
        " \n",
        "training_args = TrainingArguments(\n",
        "   output_dir=repo_name,\n",
        "   learning_rate=2e-5,\n",
        "   per_device_train_batch_size=16,\n",
        "   per_device_eval_batch_size=16,\n",
        "   num_train_epochs=2,\n",
        "   weight_decay=0.01,\n",
        "   save_strategy=\"epoch\",\n",
        ")\n",
        " \n",
        "trainer = Trainer(\n",
        "   model=model,\n",
        "   args=training_args,\n",
        "   train_dataset=tokenized_train,\n",
        "   eval_dataset=tokenized_test,\n",
        "   tokenizer=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that the defaul loss function is already cross entropy loss: [here](https://github.com/huggingface/transformers/blob/v4.17.0/src/transformers/models/bert/modeling_bert.py). \n"
      ],
      "metadata": {
        "id": "rYhXx8jM_U6o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "J60KxE62tPmL",
        "outputId": "1a09573e-cbca-459f-a616-f073d596e818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 1000\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 126\n",
            "  Number of trainable parameters = 66955010\n",
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='126' max='126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [126/126 01:44, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to finetuning-sentiment-model-3000-samples/checkpoint-63\n",
            "Configuration saved in finetuning-sentiment-model-3000-samples/checkpoint-63/config.json\n",
            "Model weights saved in finetuning-sentiment-model-3000-samples/checkpoint-63/pytorch_model.bin\n",
            "tokenizer config file saved in finetuning-sentiment-model-3000-samples/checkpoint-63/tokenizer_config.json\n",
            "Special tokens file saved in finetuning-sentiment-model-3000-samples/checkpoint-63/special_tokens_map.json\n",
            "Saving model checkpoint to finetuning-sentiment-model-3000-samples/checkpoint-126\n",
            "Configuration saved in finetuning-sentiment-model-3000-samples/checkpoint-126/config.json\n",
            "Model weights saved in finetuning-sentiment-model-3000-samples/checkpoint-126/pytorch_model.bin\n",
            "tokenizer config file saved in finetuning-sentiment-model-3000-samples/checkpoint-126/tokenizer_config.json\n",
            "Special tokens file saved in finetuning-sentiment-model-3000-samples/checkpoint-126/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=126, training_loss=0.4624747018965464, metrics={'train_runtime': 105.1295, 'train_samples_per_second': 19.024, 'train_steps_per_second': 1.199, 'total_flos': 263009880425280.0, 'train_loss': 0.4624747018965464, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lZh24el0tPmL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "ac913020-8e8a-433e-da56-bb20946ecffb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 25000\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1563/1563 07:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.308576762676239,\n",
              " 'eval_accuracy': 0.87956,\n",
              " 'eval_f1': 0.8788476240292923,\n",
              " 'eval_runtime': 441.2864,\n",
              " 'eval_samples_per_second': 56.653,\n",
              " 'eval_steps_per_second': 3.542,\n",
              " 'epoch': 2.0}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though we only run 1000 training data with 2 epochs, when we test on all the testing dataset, we achieve 88% accuracy! ⛳ We can try to use more datapoints when we have sufficient computational power or customize the BERT model to improve accuracy."
      ],
      "metadata": {
        "id": "2bYF2Syy2Txz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resources: \n",
        "- [Sentiment Analysis of IMDB Movie Reviews\n",
        "](https://www.kaggle.com/code/lakshmi25npathi/sentiment-analysis-of-imdb-movie-reviews/notebook)\n",
        "- [Sentiment Analysis - Cleaning,EDA & BERT(88% Acc)\n",
        "](https://www.kaggle.com/code/madz2000/sentiment-analysis-cleaning-eda-bert-88-acc#DATA-VISUALIZATION-AND-PREPROCESSING)\n",
        "- [Text Classification with Movie Reviews](https://www.kaggle.com/code/madz2000/sentiment-analysis-cleaning-eda-bert-88-acc#DATA-VISUALIZATION-AND-PREPROCESSING)\n",
        "- [NLP - Data Preprocessing and Cleaning](https://www.kaggle.com/code/colearninglounge/nlp-data-preprocessing-and-cleaning)\n",
        "- [Getting Started with Sentiment Analysis using Python\n",
        "](https://huggingface.co/blog/sentiment-analysis-python)\n",
        "- [BERT Explained: A Complete Guide with Theory and Tutorial](https://towardsml.wordpress.com/2019/09/17/bert-explained-a-complete-guide-with-theory-and-tutorial/)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zeLDy2zx64hd"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MAwOXDjcv66k",
        "ySOAncvV4ihV",
        "S9tiuYi44ihV",
        "JIbC2Mx_4ihW",
        "8GYhd7Ec4ihW",
        "X5OoUJ-e4ihW",
        "rfDX-AKQ4ihW"
      ]
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "45376bfead714e4e97a1c847a987c130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c56a71fad5749cfa0f9b6c1417b2ed1",
              "IPY_MODEL_f804785d4e394a06ae42016103b36978",
              "IPY_MODEL_2ec2e33a2f564fad9f64b9f61e26af45"
            ],
            "layout": "IPY_MODEL_36158f90e78e4a96bca13c6be0423782"
          }
        },
        "2c56a71fad5749cfa0f9b6c1417b2ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbe932fe87464453829335ade961855e",
            "placeholder": "​",
            "style": "IPY_MODEL_85bd186181364ab0aaa3e5c3edadda79",
            "value": "100%"
          }
        },
        "f804785d4e394a06ae42016103b36978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f42f8e8b73ff48b9a7c99a0e2e2ec470",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c34fe42478a14ee4955ee8b786c1f647",
            "value": 3
          }
        },
        "2ec2e33a2f564fad9f64b9f61e26af45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec615df4324c4c99bec0e2c0c350525a",
            "placeholder": "​",
            "style": "IPY_MODEL_9ff48cf86c0546759c648b838498a004",
            "value": " 3/3 [00:00&lt;00:00, 93.15it/s]"
          }
        },
        "36158f90e78e4a96bca13c6be0423782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbe932fe87464453829335ade961855e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85bd186181364ab0aaa3e5c3edadda79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f42f8e8b73ff48b9a7c99a0e2e2ec470": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c34fe42478a14ee4955ee8b786c1f647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec615df4324c4c99bec0e2c0c350525a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff48cf86c0546759c648b838498a004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01a545d65439435f93c79dc952329df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e21f08cc1b6e46a0866b936340c907ec",
              "IPY_MODEL_8f306f051830410ebc33a7576251a586",
              "IPY_MODEL_c56b717e10d14f15b0adfdb31bd48942"
            ],
            "layout": "IPY_MODEL_c25c6d0a8d014848a4836a3eae8e4c3d"
          }
        },
        "e21f08cc1b6e46a0866b936340c907ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5311314d4af4547af732f275bd34aa5",
            "placeholder": "​",
            "style": "IPY_MODEL_2a41816676a5466889cd978fc8eb3c40",
            "value": "Map: 100%"
          }
        },
        "8f306f051830410ebc33a7576251a586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c06a6ecb5e5e4a739d4fad05e8527353",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_418353e277fb4727ad09ddf600d23637",
            "value": 25000
          }
        },
        "c56b717e10d14f15b0adfdb31bd48942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa5eb9691a974d4d9f9b15084f6a5ac9",
            "placeholder": "​",
            "style": "IPY_MODEL_236b5fa8480d4e5aaedede12905e256e",
            "value": " 25000/25000 [00:32&lt;00:00, 784.94 examples/s]"
          }
        },
        "c25c6d0a8d014848a4836a3eae8e4c3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "a5311314d4af4547af732f275bd34aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a41816676a5466889cd978fc8eb3c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c06a6ecb5e5e4a739d4fad05e8527353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "418353e277fb4727ad09ddf600d23637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa5eb9691a974d4d9f9b15084f6a5ac9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "236b5fa8480d4e5aaedede12905e256e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}